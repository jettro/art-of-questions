{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load talk data\n",
    "Reads the csv file with all the talks and stores them into a Weaviate cluster.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efc14f8a8548ac43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "talks = pd.read_csv('./data_source/all_talks_data.csv')\n",
    "\n",
    "talks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Langchain Documents\n",
    "Transform the talks from the csv file into an array of Documents that can be used by the chain. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbaa24f71d5c7d4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "talkdocs = []\n",
    "for index, row in talks.iterrows():\n",
    "    doc = Document(page_content=row[\"Title\"],\n",
    "                   metadata={\n",
    "                       \"talk_url\": row[\"talk_url\"], \n",
    "                       \"speakers\": row[\"speakers\"],\n",
    "                       \"talk_times\": row[\"talk_times\"]\n",
    "                   })\n",
    "    talkdocs.append(doc)\n",
    "    \n",
    "print(talkdocs[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "663d8fb0152ce4d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize vector database (Weaviate)\n",
    "You can change this into another vector database if you can."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1de67953fbe03214"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from langchain.vectorstores import Weaviate\n",
    "\n",
    "\n",
    "def __init_weaviate_client() -> weaviate.Client:\n",
    "    weaviate_url = os.getenv('WEAVIATE_URL')\n",
    "\n",
    "    auth_config = weaviate.auth.AuthApiKey(\n",
    "        api_key=os.getenv('WEAVIATE_API_KEY'),\n",
    "    )\n",
    "\n",
    "    return weaviate.Client(\n",
    "        url=weaviate_url,\n",
    "        auth_client_secret=auth_config,\n",
    "        additional_headers={\n",
    "            \"X-OpenAI-Api-Key\": os.getenv('OPEN_AI_API_KEY')\n",
    "        }\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ea212266286a15a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "create the client and verify the connection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c7371879e0c1b04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wv_client = __init_weaviate_client()\n",
    "\n",
    "if wv_client.schema.exists(\"DevoxxTalk\"):\n",
    "    print(wv_client.schema.delete_class(\"DevoxxTalk\"))\n",
    "else:\n",
    "    print(\"Not available\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "777659184372530c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the documents into the vector database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e480d258e4658e92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv('OPEN_AI_API_KEY'),\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "weaviate_vs = Weaviate.from_documents(documents=talkdocs,\n",
    "                                  index_name=\"DevoxxTalk\",\n",
    "                                  embedding=openai_embeddings,\n",
    "                                  client=__init_weaviate_client(),\n",
    "                                  by_text=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57b0bc2fd1033c02"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verify the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "343a4f87dad09679"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"What talks deal with large language models?\"\n",
    "results = weaviate_vs.similarity_search_with_score(query)\n",
    "\n",
    "for result in results:\n",
    "    document, score = result \n",
    "    print(f\"score: {score}\\n {document.page_content}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91e48d686edad314"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

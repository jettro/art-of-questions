{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Check your environment\n",
    "In this Notebook, you check the correct setup of your environment. You load the environment using the file _.env_. You have to create the file yourself. We did provided a template to use for the file. The template is called [template-env](file://./template-env).\n",
    "\n",
    "In the next code block, you import all available variables in the _.env_ file into the environment files. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd7fd05299efec71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if load_dotenv(dotenv_path=\"./.env\"):\n",
    "    print(\"All environment variables are loaded\")\n",
    "else:\n",
    "    print(\"We cannot find the file '.env' in the root of your project. Please use the template 'template-env' to create one. \"\n",
    "          \"Run this cell again to retry the loading of the file. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Python notebooks has a simple command to show all the system variables. Go ahead, try it out. Add a new code cell and run the following command in the code cell.\n",
    "\n",
    "```Jupyter\n",
    "# Print the environment variables\n",
    "%env\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "576a6d483e05ce10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next code block provides some utility function to check for existing keys that we require. We check for three variables:\n",
    "```text\n",
    "OPENAI_API_KEY\n",
    "HUGGINGFACEHUB_API_TOKEN\n",
    "WEAVIATE_API_KEY\n",
    "WEAVIATE_CLUSTER_URL\n",
    "```\n",
    "\n",
    "Allthough you can run everything on your local machine, we recommend getting used to working with remote services. Using the remote services makes you less dependend on having all the different services running on your local machine. Below are are a few links that help you to obtain the right keys.\n",
    "\n",
    "- [OpenAI API Key](https://beta.openai.com/account/api-keys)\n",
    "- [HuggingFace API Key](https://huggingface.co/settings/tokens)\n",
    "- [Weaviate console to create a cluster](https://console.weaviate.cloud/)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98ef04f12340c6f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def verify_environment_keys() -> dict:\n",
    "    \"\"\"Parse known environment variables and return their availability in a dict\"\"\"\n",
    "    return {\n",
    "        \"OPENAI_API_KEY\": verify_environment_key(\"OPENAI_API_KEY\", \"OpenAI\"),\n",
    "        \"HUGGINGFACEHUB_API_TOKEN\": verify_environment_key(\"HUGGINGFACEHUB_API_TOKEN\", \"Hugging Face\"),\n",
    "        \"WEAVIATE_API_KEY\": verify_environment_key(\"WEAVIATE_API_KEY\", \"Weaviate Key\"),\n",
    "        \"WEAVIATE_CLUSTER_URL\": verify_environment_key(\"WEAVIATE_CLUSTER_URL\", \"Weaviate Cluster\")\n",
    "    }\n",
    "\n",
    "def verify_environment_key(key: str, remote_system: str) -> bool:\n",
    "    \"\"\"Verify if the provided key exists in the environment. Returns a bool indicating if the key exists\"\"\"\n",
    "    try:\n",
    "        found_key = os.environ[key]\n",
    "    except KeyError as e:\n",
    "        print(f\"Please set the key {key} in the .env file if you want to work with {remote_system}\")\n",
    "        found_key = None\n",
    "\n",
    "    return found_key is not None\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4dc7e02ee473272"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = verify_environment_keys()\n",
    "print(\"\\nOverview of all found and missing environment variables:\")\n",
    "for key in results.keys():\n",
    "    print(f\"{'found' if results[key] else 'ERROR':6s} - {key}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f094ecce0d586a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check the connection to OpenAI\n",
    "After providing the environment variable, you can connect to the OpenAI API. The following code block is an example request to OpenAI. Beware, execting these commands will cost money. Especially if you do it a lot of times. We advise to add boundaries to OpenAI for how much money you want to spend as a maximum."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc90ea60e4c0f24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What kind of conference is Devoxx?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_response[\"choices\"][0][\"message\"][\"content\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fc033533bc6527b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check the connection to HuggingFace\n",
    "After providing the environment variable, you can connecto the HuggingFace API endpoint. The following code block is an exmaple request to HuggingFace. At HuggingFace you can choose to use open source models. They are available without payment, the amount of requests are limited though."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61cba222fb9e9c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from huggingface_hub.inference_api import InferenceApi\n",
    "\n",
    "hf_repo_id = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "hf_client = InferenceApi(\n",
    "    repo_id=hf_repo_id,\n",
    "    token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    ")\n",
    "\n",
    "payload = {\n",
    "            \"source_sentence\": \"Devoxx is a conference for software developers and programmers\",\n",
    "            \"sentences\": [\n",
    "                \"Truck drivers should go to Devoxx\",\n",
    "                \"Java developers have to go to Devoxx\",\n",
    "                \"Truckload 2023 is where every Java Programmer should be\",\n",
    "                \"Real truck drivers attend Truckload 2023\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "embed_response = hf_client(inputs=payload)\n",
    "\n",
    "for sentence, score in zip(payload[\"sentences\"],embed_response):\n",
    "    print(f\"similarity score: {score} for sentence '{sentence}'\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bfa796e3d33516"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to run the HuggingFace from your own machine, please run the following code block as well."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ca3a8dc0c840a1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sentence_transformers\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "hf_model = sentence_transformers.SentenceTransformer(model_name_or_path=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "embed_source = hf_model.encode(payload[\"source_sentence\"], convert_to_numpy=True)\n",
    "embed_sentences = hf_model.encode(payload[\"sentences\"], convert_to_numpy=True)\n",
    "\n",
    "cosine = np.dot(embed_sentences,embed_source)/(norm(embed_sentences, axis=1)*norm(embed_source))\n",
    "\n",
    "for sentence, score in zip(payload[\"sentences\"],cosine):\n",
    "    print(f\"similarity score: {score} for sentence '{sentence}'\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2af9f1ac03bbe8a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check the connection to Weaviate\n",
    "You need to store vectors later on, one way of storing them is using the Weaviate vector database. If you want to use Weaviate, you need to create a cluster and copy the custer url as well as the api key to the _.env_ file. Next you check if the connection works."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec71800c34b4478b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "auth_config = weaviate.AuthApiKey(api_key=os.getenv('WEAVIATE_API_KEY'))  # Replace w/ your Weaviate instance API key\n",
    "\n",
    "# Instantiate the client with the auth config\n",
    "weaviate_client = weaviate.Client(\n",
    "    url=os.getenv('WEAVIATE_CLUSTER_URL'),  # Replace w/ your endpoint\n",
    "    auth_client_secret=auth_config\n",
    ")\n",
    "\n",
    "if weaviate_client.is_ready():\n",
    "    print(\"You are connected to Weaviate\")\n",
    "else:\n",
    "    print(\"Something is wrong with your connection to Weaviate\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "333172f742ea62d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
